# -*- coding: utf-8 -*-
"""Predict Customer Chunk

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16ICSf4D2vuXgYopkpIW3j7WgJwbVckE-
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('Churn.csv')

df.head()



df.shape

df.columns.values

df.isna().sum()

df.describe()

df['Churn'].value_counts()

sns.countplot(df['Churn'])

#What percentage of customers are leaving ?

retained = df[df.Churn == 'No']
churned = df[df.Churn == 'Yes']
num_retained = retained.shape[0]
num_churned = churned.shape[0]

print( num_retained / (num_retained + num_churned) * 100)
print( num_churned / (num_retained + num_churned) * 100)

#visualize the churn count for both males and females
sns.countplot(x='gender', hue='Churn',data = df)

sns.countplot(x='InternetService', hue='Churn', data = df)

numerical_features = ['tenure', 'MonthlyCharges']
fig, ax = plt.subplots(1, 2, figsize=(28, 8))
df[df.Churn == 'No'][numerical_features].hist(bins=20, color="blue", alpha=0.5, ax=ax)
df[df.Churn == 'Yes'][numerical_features].hist(bins=20, color="orange", alpha=0.5, ax=ax)

#Remove the unnecessary column
cleaned_df = df.drop('customerID', axis=1)

cleaned_df

cleaned_df.shape

for column in cleaned_df.columns:
        if cleaned_df[column].dtype == np.number:
            continue
        cleaned_df[column] = LabelEncoder().fit_transform(cleaned_df[column])

cleaned_df.dtypes

#Scale the value

X = cleaned_df.drop('Churn', axis = 1) #Feature Data
y = cleaned_df['Churn'] #Target Data

# Standardizing/scaling the features
X = StandardScaler().fit_transform(X)

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(x_train, y_train)

predictions = model.predict(x_test)

print(predictions)

print( classification_report(y_test, predictions) )

